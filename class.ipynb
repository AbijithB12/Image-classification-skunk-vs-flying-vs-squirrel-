# !pip install bing-image-downloader
# !mkdir images
# from bing-image-downloader import downloader
# downloader.download("SEARCH-NAME",lim,dir,adult_fil=off)
#immport
import os # to chnage folder
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn import svm
from skimage.io import imread #opencv can be used
from skimage.transform import resize #for resizing all image - all in same pixel 
#images - flatten to/ 1d 

# !pip install streamlit
# !pip install pyngrok
from pyngrok import ngrok

# !pip install bing-image-downloader
# from bing_image_downloader import downloader
# downloader.download("chipmunk",limit=10,output_dir='/content/drive/MyDrive/machine learning/Images')

# to find uti time of downloading - 1 spec cell exec time
# !pip install ipython-autotime
# %load_ext

#downloader.download("skunk",limit=10,output_dir='/content/drive/MyDrive/machine learning/Images')
#downloader.download("flying squirrel",limit=10,output_dir='/content/drive/MyDrive/machine learning/Images')
# # 2.Scrape images
# !git clone https://github.com/ultralytics/flickr_scraper
# cd flickr_scraper
# pip install -U -r requirements.txt
#flickrapi installed


# key = ''
# secret = ''
# cd flickr

# !git clone https://github.com/ultralytics/flickr_scraper


# cd flickr_scraper


# key = ''
# secret = ''

# python3 flickr_scraper.py --search 'honeybees on flowers' --n 10 --download

#2.Scrape images
#preproce
# 1.resiz
# 2.flate


tgt=[]
imgs=[]
flat_data=[]
Dir='/content/drive/MyDrive/machine learning/images'
Cate=['flying','skunk','squirrel']

for c in Cate:
  class_num=Cate.index(c)
  path=os.path.join(Dir,c)
  #print(class_num)  
  #print(path)
  for img in os.listdir(path):
    #print(img)
    img_array=imread(os.path.join(path,img))
    #print(os.path.join(path,img))
    #plt.imshow(img_array)
    img_r=resize(img_array,(150,150,3)) #150 -arbi size and 3-cchannel proba -noralizing
    flat_data.append(img_r.flatten())
    tgt.append(class_num)
    imgs.append(img_r)
    #print(img_r.shape)
    #plt.imshow(img_r)
    #plt.show()
flat_data=np.array(flat_data)    
tgt=np.array(tgt)
imgs=np.array(imgs) 
  

len(flat_data[0])

tgt

np.unique(tgt)

unique,count=np.unique(tgt,return_counts=True)
plt.bar(Cate,count)

#split


x_train, x_test, y_train, y_test = train_test_split(flat_data,tgt, test_size=0.3, random_state=42)


param_grid = [
  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
 ]
svc=svm.SVC(probability=True)
clf=GridSearchCV(svc,param_grid)
clf.fit(x_train,y_train)



y_pred=clf.predict(x_test)
y_pred

y_test

from sklearn.metrics import accuracy_score,confusion_matrix

accuracy_score(y_pred,y_test)

confusion_matrix(y_pred,y_test)

#save

import pickle
pickle.dump(clf,open('img_model.p','wb'))

model=pickle.load(open('img_model.p','rb'))

#test
flat_data=[]
url=input('enter your url')
img=imread(url)
img_r=resize(img,(150,150,3))
flat_data.append(img_r.flatten())
flat_data=np.array(flat_data)
print(img.shape)
plt.imshow(img_r)
y_out=model.predict(flat_data)
y_out=Cate[y_out[0]]
print(f'Predicted op:{y_out}')

# #dploy
# 1.webpage -flash /django
# 2.webapp -streamlit/Dash
# 3.mobileapp - kotlin/java

%%writefile app.py
import streamlit as st
st.title('image classifier')

!nohup streamlit run app.py &
url=ngrok.connect(port='8501')
url



